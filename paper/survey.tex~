\documentclass{article}
\usepackage{amsmath,graphicx}

\begin{document}
\section{notes}
SPP is trying to avoid data augmentation . But the latest one introducing it model more sophisticated system.

\section{Spatial pyramid pooling in Deep Convolutional Networks}
Instead of using fixed input size in CNNs, Kaiming He et al.\cite{} suggested  a method to add  another spooling strategy called  spatial pyramid pooling(SPP) to avoid cropping or warping of  images . It introduced an new layer on top of convolution layer and perform aggregation  based on Bag-of-Words (BoW) model \cite{bow}. But the classical back propagation training methods expect layers to have fixed   size. To overcome this problem authors implemented two fixed size networks with shared parameters and switch the network on alternate epochs. This network is trained using a single GeForce GTX Titan GPU with a starting  learning rate of 0.01 and achieved  a less  error rate of 8.06\% on  ILSVRC 2014 data set. 
\par 
This implementation improves the performance of baseline architectures including ZF-5\cite{zf5} , Convnet \cite{Krizhevsky} and Overfeat-5/7 \cite{of}. Their study shows , accuracy of CNNs will improve on multi-size training, multi-level pooling and full-image representations. 
%

\section{Going deeper with convolutions }
Christian Szegedy and et al.\cite{Szegedy} proposed a network named GoogLeNet with receptive field(input layer) of size $244*244$ with number of layers around 100. Network is trained using asynchronous stochastic gradient descent with 0.9 momentum and fixed learning rate schedule based on  no of epochs 
. Learning procedure took advantage of  model and data-parallelism in a CPU based cluster environment. This network gave an error rate of  6.67\%  on  ILSVRC 2014 data set. Their result shows that use of existing dense  blocks to  build the sparse structure can improve the  performance of convolutional networks.


\section{VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION}
Karen Simonyan and Andrew Zisserman \cite{Arge2015} evaluated the effect of network depth in image classification using very small convolution filters. Their deep network architecture comprise of fixed  size input layers , a stack of convolution layers , three Fully-Connected (FC) layers and  5 max-pooling layers for spatial spooling  over a $2 x 2$ pixel window with stride 2. Hidden layers are modeled using Rectified Linear Units(ReLU)\cite{Nair2010}. On the hardware side , it uses a multi-GPU system with NVIDIA Titan Black GPUs. Netwok is trained using multinomial logistic regression  based on back-propagation with momentum of 0.9 and  batch size  256.
\par
 In this work authors formed a conclusion that greater depth with small convolution filters and  preinitialization of certain layers will cause the learning process to converge in less number  of epochs. This model of convolution network does not differ from the classical architecture proposed by  LeCun et al.\cite{LeCun1998}. But the authors reported a significant improvement in the performance using an increased depth.  This implementation results in a significant improvement with  an error rate of  6.8\% in  ILSVRC 2014 of ImageNet.

\begin{section}{Deep Image: Scaling up Image Recognition}
The latest attempt in image classification with an error 5.98\% in ImageNet data set is reported by  Ren Wu et al.\cite{Wu2015} of Baidu research.They developed an end to end deep learning  system named Deep Image. It uses a highly optimized parallel algorithm  to implement large deep neural network with augmented input data. The network is trained using stochastic gradient decent algorithms (SGD)[ref] on a custom built high performance system comprised of 36 server nodes, each with 2 six-core Intel Xeon E5-2620 processors and 4 NVIDIA Tesla K40m GPUs . System  uses an InfiniBand  network for interconnections. Parallelism strategies used in their network are model-data parallelism and data parallelism.  This methods have been proposed by Alex Krizhevsky \cite{Krizhevsky2014} and Omry Yadan et al.\cite{Yadan2013} for training convolutional neural networks with SGD on a  multiple GPU systems. But it is not easy extend the same strategies to multiple GPU cluster because of the communication overhead. So the  Baidu Team focused on minimizing network data transfers and overlapping the computation. They uses butterfly synchronization and lazy update strategies to achieve data parallelism in gradient computation. Their results shows model-data parallelism is better when number of GPUs is less than 16. Implementation of Data parallelism in large number  of GPU  cluster is better because of the constant communication requirements.
\par
The authors have explored different data augmentation techniques to increase the number of labeled images in the training set. This includes color casting, Vignetting , Lens distortion , Rotation , Flipping and  Cropping. Instead of using the same resolution on all images, they have trained separate models at different scales, combined results by averaging softmax class posteriors.
Data set used in this experiment was subset of ImageNet data set , used in the competition ImageNet Large-Scale Visual Recognition Challenge (ILSVRC)\cite{Berg2010}. This data set includes 1.2 million images which contains 1,000 categories.
\par
 Major contribution of this work is the demonstration of tremendous computational power to achieve high accuracy in image classification.
It also shows , augmented multi-scale images can be combined to achieve less error rate in convolutional network in the context of the image classification . 
 \end{section}




\section{REFERENCES}
\label{sec:survey}
\bibliographystyle{IEEEbib}
\bibliography{survey}

\end{document}
